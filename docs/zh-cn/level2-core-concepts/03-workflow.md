# 第三章：LangGraph 工作流

## 学习目标

完成本章节学习后，你将能够理解 LangGraph 框架的基本概念和设计原理，了解系统状态图的结构和各节点的功能，理解智能体协作的数据流和控制流，以及掌握工作流的执行流程和配置方法。预计学习时间为 1-2 小时。

## 3.1 LangGraph 框架概述

### 什么是 LangGraph

LangGraph 是基于 LangChain 构建的状态图框架，专门用于构建复杂的多智能体工作流。它将工作流建模为图结构，其中节点（Node）代表计算单元，边（Edge）代表数据和控制流动的方向。这种图模型能够优雅地表达复杂的协作模式，如并行执行、条件分支、循环等。

在 AI Hedge Fund 系统中，LangGraph 被用于编排 18 个智能体的协作流程。它定义了每个智能体何时被调用、数据如何在智能体之间传递、最终决策如何生成等核心逻辑。

### 状态图的核心概念

**节点（Node）**：图中的基本计算单元，每个节点执行特定的功能。在系统中，节点包括开始节点、智能体节点、风险管理节点和投资组合管理节点等。

**边（Edge）**：连接节点的边定义数据流动的方向。普通边表示确定性的流动；条件边根据状态值决定下一个要执行的节点。

**状态（State）**：贯穿整个工作流的数据结构，包含当前分析所需的所有信息。状态在节点之间传递和更新。

**检查点（Checkpoint）**：工作流执行过程中的快照，用于恢复和调试。

### 状态图的优势

使用 LangGraph 构建工作流有几个显著优势。**可视化**：状态图结构清晰，易于理解和调试。**灵活性**：可以轻松添加、删除或重新排列节点。**并行支持**：天然支持并行执行，提高效率。**容错性**：支持从检查点恢复，应对执行失败。

## 3.2 系统状态图结构

### 状态定义

系统的核心状态定义在 `src/graph/state.py` 文件中，使用 Python 的 TypedDict 定义。状态包含以下主要字段：

**messages**：消息历史，记录整个分析过程中的所有消息。类型为 `Annotated[Sequence[BaseMessage], operator.add]`，表示消息会累积追加。

**data**：分析数据字典，包含所有分析相关的数据。主要字段包括：
- `tickers`：待分析的股票代码列表
- `portfolio`：投资组合状态
- `analyst_signals`：各智能体的分析信号
- `start_date`：分析开始日期
- `end_date`：分析结束日期

**metadata**：元数据，包含运行配置：
- `show_reasoning`：是否显示详细推理
- `model_name`：使用的模型名称
- `model_provider`：模型提供商

### 图结构概览

```
┌─────────────────────────────────────────────────────────────────┐
│                     状态图完整结构                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ┌─────────────┐                                               │
│   │  start_node │ ← 入口点                                      │
│   └──────┬──────┘                                               │
│          │                                                       │
│          ▼                                                       │
│   ┌─────────────────────────────────────────────────────────┐   │
│   │              并行执行选中智能体                           │   │
│   │  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐       │   │
│   │  │ Buffett │ │ Graham  │ │ Lynch   │ │ Wood    │ ...   │   │
│   │  └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘       │   │
│   └───────┼──────────┼──────────┼──────────┼─────────────┘   │
│           │          │          │          │                    │
│           └──────────┴──────────┴──────────┘                    │
│                          │                                       │
│                          ▼                                       │
│               ┌─────────────────────┐                            │
│               │ risk_management_agent│ ← 风险管理节点            │
│               └──────────┬──────────┘                            │
│                          │                                       │
│                          ▼                                       │
│               ┌─────────────────────┐                            │
│               │  portfolio_manager  │ ← 投资组合管理节点        │
│               └──────────┬──────────┘                            │
│                          │                                       │
│                          ▼                                       │
│                         END                                       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 节点详解

**start_node**：入口节点，负责初始化分析任务。它接收用户输入（股票代码、时间范围等），创建初始状态，然后触发智能体分析。

**智能体节点**：每个智能体对应一个节点，如 `warren_buffett_agent`、`technical_analyst_agent` 等。这些节点并行执行（由 LangGraph 调度），每个节点调用对应的智能体进行独立分析。

**risk_management_agent**：风险管理节点，汇总所有智能体的信号，进行风险评估，计算推荐的仓位和止损设置。

**portfolio_manager**：投资组合管理节点，综合所有输入（智能体信号、风险评估），生成最终的交易决策。

## 3.3 工作流执行流程

### 初始化阶段

当用户发起分析请求时，工作流执行以下初始化步骤：

**步骤一：接收输入**。用户通过命令行或 Web API 提供股票代码、时间范围等参数。

**步骤二：创建状态**。`start_node` 创建初始状态对象，包含所有必要的配置信息。

**步骤三：数据获取**。系统调用金融数据 API，获取分析所需的市场数据。

**步骤四：广播到智能体**。状态被传递给所有选中的智能体节点，准备并行分析。

### 分析阶段

**并行执行**：LangGraph 调度所有智能体节点并行执行。每个智能体独立完成以下步骤：

```
对于每个智能体节点：
1. 读取当前状态，获取股票数据和配置
2. 构建分析提示词
3. 调用 LLM 进行推理
4. 解析 LLM 输出，生成结构化信号
5. 更新状态，添加分析结果
6. 返回控制权
```

**结果汇总**：所有智能体完成后，它们的结果被汇总到共享状态中。汇总内容包括每个智能体的信号、置信度和推理。

### 决策阶段

**风险管理**：风险管理节点接收汇总后的智能体信号，执行以下分析：

- 计算组合的整体风险水平
- 评估各信号的一致性和冲突
- 基于波动率调整推荐仓位
- 设置止损和获利了结参数

**最终决策**：投资组合管理节点综合所有输入，生成最终决策：

- 汇总各股票的推荐操作
- 计算最优仓位分配
- 生成结构化的交易建议

### 输出阶段

最终状态被序列化为用户可读的格式输出，包括各智能体的分析结果、风险评估和最终决策。

## 3.4 工作流配置

### 选择智能体

用户可以通过 `--analysts` 参数选择参与分析的智能体：

```bash
poetry run python src/main.py --ticker AAPL --analysts warren_buffett,ben_graham,technical_analyst
```

在代码层面，智能体选择影响状态图的构建。只有被选中的智能体才会被添加到图中并连接到风险管理节点。

### 自定义配置

工作流支持多种自定义配置：

**模型配置**：通过 `--model` 参数选择 LLM 提供商，支持 `openai`、`anthropic`、`groq`、`deepseek` 等。

**输出详细度**：通过 `--show-reasoning` 参数控制是否显示详细推理过程。

**风险偏好**：通过 `--risk-tolerance` 参数调整风险偏好，影响推荐的仓位大小。

### 配置文件支持

对于复杂的配置，可以使用 YAML 配置文件：

```yaml
workflow:
  default_analysts:
    - warren_buffett
    - charlie_munger
    - technical_analyst
  model: anthropic
  show_reasoning: true
  risk_tolerance: 5
```

## 3.5 错误处理与恢复

### 检查点机制

LangGraph 支持检查点功能，可以保存工作流执行过程中的状态快照。如果执行中断，可以从最近的检查点恢复，而不是从头开始。

检查点在以下情况下保存：每个节点执行完成后；发生错误时；用户请求保存。

### 错误处理策略

系统采用以下错误处理策略：

**智能体重试**：如果单个智能体调用失败（如 LLM 超时），会自动重试一次。如果重试仍然失败，会记录错误并继续处理其他智能体。

**部分失败容忍**：即使部分智能体失败，系统仍会尝试完成整体分析。失败的智能体在结果中会被标记为「不可用」。

**用户通知**：当发生非致命错误时，系统会向用户报告错误信息和建议操作。

### 调试模式

启用 `--show-reasoning` 参数后，系统会输出更详细的执行日志，包括每个节点的输入、输出和执行时间。这些信息对于调试和分析性能瓶颈非常有用。

## 3.6 性能考量

### 并行优化

LangGraph 自动调度智能体节点的并行执行。并行度受以下因素限制：LLM API 的速率限制；本地计算资源（CPU、内存）；API 提供商的并发限制。

### 缓存策略

系统实现了多层缓存以提高性能：

**数据缓存**：金融数据被缓存以避免重复请求。缓存键基于股票代码、日期范围和数据类型生成。

**LLM 响应缓存**：相同的查询可能被缓存（需要启用），但由于 LLM 的非确定性特征，缓存命中率通常较低。

### 资源管理

长时间运行的工作流会消耗显著的资源。系统采取以下措施管理资源：限制并发智能体数量；设置 LLM 调用超时；自动清理中间状态。

## 3.7 练习题

### 练习 3.1：状态图绘制

**任务**：绘制简化版的状态图，标记所有节点和边。

**要求**：至少包含开始节点、3 个智能体节点、风险管理节点和结束节点。标注边的类型（普通边或条件边）。

### 练习 3.2：执行流程追踪

**任务**：追踪一条分析请求的执行流程。

**步骤**：首先执行命令 `python src/main.py --ticker AAPL --analysts warren_buffett --show-reasoning`，然后记录每个阶段的输入、输出和耗时。

**要求**：绘制时间线图，展示各阶段的执行顺序和耗时分布。

### 练习 3.3：配置实验

**任务**：比较不同配置下的分析结果。

**实验一**：比较全部智能体和部分智能体的结果差异。实验二：比较不同 LLM 提供商的分析结果。实验三：比较不同风险偏好的推荐仓位差异。

**要求**：记录和分析实验结果，总结各配置的影响。

---

## 进阶思考

思考以下问题。LangGraph 的状态图模型与其他工作流引擎（如 Airflow、Dagster）相比有什么优势和局限？如何设计更复杂的工作流，如包含条件分支或循环的流程？工作流的哪些部分适合在 GPU 上加速执行？

下一章节我们将学习数据获取和缓存管理的实现原理。

---

## 版本信息

| 项目 | 信息 |
|------|------|
| 文档版本 | 1.0.2 |
| 最后更新 | 2026年2月 |
| 适用版本 | 1.0.0+ |

**更新日志**：
- v1.0.2 (2026.02)：更新状态图结构说明，增加性能考量章节
- v1.0.1 (2025.12)：完善错误处理机制说明
- v1.0.0 (2025.10)：初始版本

## 反馈与贡献

如果您在阅读过程中发现问题或有改进建议，欢迎通过 GitHub Issues 提交反馈。
